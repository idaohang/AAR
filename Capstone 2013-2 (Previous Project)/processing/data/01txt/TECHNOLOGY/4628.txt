This research is investigating the feasibility of using computer vision to provide a level of situational awareness suitable for the task of UAV &quot;sense and avoid.&quot; This term is used to describe the capacity of a UAV to detect airborne traffic and respond with appropriate avoidance maneuvers in order to maintain minimum separation distances. As reflected in regulatory requirements such as FAA Order 7610.4, this capability must demonstrate a level of performance which meets or exceeds that of an equivalent human pilot.    Presented in this paper is a comparison between two initial image processing algorithms that have been designed to detect small, point-like features (potentially corresponding to distant, collision course aircraft), from image streams and a discussion of their performance in processing a real-life collision scenario. This performance is compared against the stated benchmark of equivalent human performance, specifically the measured detection times of an alerted human observer.    The two algorithms were used to process a series of image featuring real collision course aircraft against a variety of daytime backgrounds. Preliminary analysis of this data set has yielded encouraging results, achieving first detection times at distances of approximately 6.5km (3.5nmi), which are 35-40% greater than those of an alerted human observer. Comparisons were also drawn between the two separate detection algorithms, and have demonstrated that a new approach designed to increase resilience to image noise achieves a lower rate of false alarms, particularly in tests featuring more sensitive detection thresholds.
